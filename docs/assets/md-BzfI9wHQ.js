import{_,a as b}from"./slidev/VClick-gve6EVk6.js";import{aJ as i,b as w,o,w as r,g as t,ah as s,e as a,f as l,ad as e,v as h,x as v,T as d}from"./modules/vue-C_Pw_zrB.js";import{_ as y}from"./rl-BApXEysj.js";import{_ as k}from"./default-BA1rUQQh.js";import{u as x,f as L}from"./slidev/context-BgWHCmGd.js";import{_ as D}from"./index-C5gLzTxT.js";import"./modules/shiki-BkbMiWXR.js";const E="/assets/sde-BdYI-EcG.png",q={__name:"slides.md__slidev_4",setup(B){const{$clicksContext:c,$frontmatter:m}=x();return c.setup(),(R,n)=>{const u=_,p=b,g=i("click"),f=i("after");return o(),w(k,h(v(d(L)(d(m),3))),{default:r(()=>[n[3]||(n[3]=t("h2",null,"Key Contributions",-1)),n[4]||(n[4]=t("p",null,"We propose the first model-free reinforcement learning algorithm for continuous-time systems whose dynamics are governed by stochastic differential equations.",-1)),s((o(),l("div",null,[a(u,null,{default:r(()=>n[0]||(n[0]=[t("div",null,[t("strong",null,"Reinforcement Learning (RL)"),t("br"),e(" - "),t("strong",{class:"accent"},"A machine learning framework for decision-making"),e(", widely used in robotics, game AI, and LLM training."),t("br"),e(" - Traditionally formulated as an optimization problem over systems with "),t("strong",{class:"accent"},"discrete state transitions"),e("."),t("br"),t("figure",{style:{position:"absolute",top:"59%",right:"60%",width:"250px","text-align":"center"}},[t("img",{src:y,style:{width:"100%"}}),t("figcaption",{style:{"font-size":"1.2em","word-wrap":"break-word","margin-top":"4px"}}," training process of RL ")])],-1),t("div",null,[t("strong",null,"Stochastic Differential Equation (SDE)"),t("br"),e(" - "),t("strong",{class:"danger"},"A differential equation"),e(" with randomness. "),t("figure",{style:{position:"absolute",top:"59%",right:"20%",width:"300px","text-align":"center"}},[t("img",{src:E,style:{width:"100%"}}),t("figcaption",{style:{"font-size":"1.2em","word-wrap":"break-word","margin-top":"-6px"}}," paths of SDE ")])],-1)])),_:1,__:[0]})])),[[g,void 0,void 0,{hide:!0}]]),s((o(),l("div",null,n[1]||(n[1]=[t("strong",null,"Reinforcement Learning (RL)",-1),t("br",null,null,-1),e(" - "),t("strong",{class:"accent"},"A machine learning framework for decision-making",-1),e(", widely used in robotics, game AI, and LLM training."),t("br",null,null,-1),e(" - Traditionally formulated as an optimization problem over systems with "),t("strong",{class:"accent"},"discrete state transitions",-1),e("."),t("br",null,null,-1),t("strong",null,"Stochastic Differential Equation (SDE)",-1),t("br",null,null,-1),e(" - "),t("strong",{class:"danger"},"A differential equation",-1),e(" with randomness. "),t("div",{style:{border:"2px solid #000",padding:"10px",margin:"15px auto","background-color":"rgb(243, 255, 243)"}},[t("strong",null,"Engineering Perspective"),t("br"),e(" Bridges stochastic control and RL: Both target the same objective â€” the former relies on analytical solutions under assumptions, whereas the latter (ours) learns purely from data without such assumptions. ")],-1)]))),[[f]]),a(p,null,{default:r(()=>n[2]||(n[2]=[t("div",{style:{border:"2px solid #000",padding:"10px",margin:"10px auto","background-color":"rgb(255, 235, 240)"}},[t("strong",null,"Difference from Previous Work"),t("br"),e(" Prior works require explicit knowledge of the system dynamics, limiting applications to toy problems like pendulums."),t("br"),e(" In contrast, our method requires no knowledge of the dynamics and can be applied to any continuous system. ")],-1)])),_:1,__:[2]})]),_:1,__:[3,4]},16)}}},N=D(q,[["__scopeId","data-v-557c7353"]]);export{N as default};
